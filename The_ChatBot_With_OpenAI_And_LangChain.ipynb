{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPyLmKojGGwP"
      },
      "outputs": [],
      "source": [
        "# Installing necessary libraries\n",
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install gradio\n",
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing required modules\n",
        "import os\n",
        "import gradio as gr\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import LLMChain, PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory"
      ],
      "metadata": {
        "id": "OJfjEJbwGmbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How to get Open AI API Key?**\n",
        "- Go to https://platform.openai.com/account/api-keys\n",
        "- Create a new Secret Key\n",
        "- Copy the Secret Key for your use."
      ],
      "metadata": {
        "id": "VclINVmUGsb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the OpenAI API key\n",
        "OPENAI_API_KEY = \"YOUR_OPENAI_API_KEY\"  # Replace with your actual OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "fci9byLAGrW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the chat template and memory buffer\n",
        "template = \"\"\"You are a helpful assistant to answer user queries.\n",
        "{chat_history}\n",
        "User: {user_message}\n",
        "Chatbot:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(input_variables=[\"chat_history\", \"user_message\"], template=template)\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
      ],
      "metadata": {
        "id": "r7AnNKzZG2FO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Similar to Open AI Mondel we can also use HuggingFace Transformer Models.\n",
        "- Reference links: https://python.langchain.com/docs/integrations/providers/huggingface , https://python.langchain.com/docs/integrations/llms/huggingface_hub.html\n",
        "\n"
      ],
      "metadata": {
        "id": "JhO7eYfNRGU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.llms import HuggingFacePipeline\n",
        "# hf = HuggingFacePipeline.from_model_id(\n",
        "#     model_id=\"gpt2\",\n",
        "#     task=\"text-generation\",)"
      ],
      "metadata": {
        "id": "PvYWPZnSQr02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the Language Model Chain\n",
        "llm_chain = LLMChain(\n",
        "    llm=ChatOpenAI(temperature='0.5', model_name=\"gpt-3.5-turbo\"),  # Initializing the GPT-3.5-Turbo language model\n",
        "    prompt=prompt,\n",
        "    verbose=True,  # Enabling verbose mode for the language model chain\n",
        "    memory=memory,  # Associating the conversation buffer memory with the language model chain\n",
        ")"
      ],
      "metadata": {
        "id": "IdEV6hMJG4xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to retrieve text response from the chatbot\n",
        "def get_text_response(user_message, history):\n",
        "    response = llm_chain.predict(user_message=user_message)  # Getting response from the language model chain\n",
        "    return response"
      ],
      "metadata": {
        "id": "Wl77cfyIG85T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the Gradio Chat Interface with some example queries\n",
        "demo = gr.ChatInterface(get_text_response, examples=[\"How are you doing?\", \"What are your interests?\", \"Which places do you like to visit?\"])"
      ],
      "metadata": {
        "id": "0JxyOMt_HAr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    demo.launch(share=True, debug=True)  # Launching the Gradio interface for the chatbot with share and debug options enabled"
      ],
      "metadata": {
        "id": "sWVT_2_KHE2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Publishing your code to Hugging Face**"
      ],
      "metadata": {
        "id": "YLLzAlLeIlcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logging into Hugging Face\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "ZmFkrSfFI2hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an API object for Hugging Face\n",
        "from huggingface_hub import HfApi\n",
        "api = HfApi()"
      ],
      "metadata": {
        "id": "3ijRWEjlI8NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the Hugging Face repository ID\n",
        "HUGGING_FACE_REPO_ID = \"<Hugging Face User Name/Repo Name>\"  # Replace with your actual Hugging Face repository ID"
      ],
      "metadata": {
        "id": "zPcVNQxpJBT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding Secret Variables in Hugging Face Account:**\n",
        "\n",
        "- Open your Space\n",
        "- Click on Settings Button\n",
        "- Checkout to **Variables and secrets** section\n",
        "- Create New Secrets"
      ],
      "metadata": {
        "id": "Jc4apOwzTzYS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Note*: Make sure to add your **OPENAI_API_KEY** in Secret key"
      ],
      "metadata": {
        "id": "LAj6X5xwJWGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a directory for the chatbot and downloading necessary files\n",
        "%mkdir /content/ChatBotWithOpenAI\n",
        "!wget -P /content/ChatBotWithOpenAI/ https://s3.ap-south-1.amazonaws.com/cdn1.ccbp.in/GenAI-Workshop/ChatBotWithOpenAIAndLangChain/app.py\n",
        "!wget -P /content/ChatBotWithOpenAI/ https://s3.ap-south-1.amazonaws.com/cdn1.ccbp.in/GenAI-Workshop/ChatBotWithOpenAIAndLangChain/requirements.txt"
      ],
      "metadata": {
        "id": "d9LOTbYubojs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing directory to the ChatBotWithOpenAI directory\n",
        "%cd /content/ChatBotWithOpenAI\n",
        "\n",
        "# Uploading the files to the Hugging Face repository\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"./requirements.txt\",\n",
        "    path_in_repo=\"requirements.txt\",\n",
        "    repo_id=HUGGING_FACE_REPO_ID,\n",
        "    repo_type=\"space\"\n",
        ")\n",
        "\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"./app.py\",\n",
        "    path_in_repo=\"app.py\",\n",
        "    repo_id=HUGGING_FACE_REPO_ID,\n",
        "    repo_type=\"space\"\n",
        ")"
      ],
      "metadata": {
        "id": "nF-XF-_gJF8g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}